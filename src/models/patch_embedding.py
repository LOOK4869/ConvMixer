"""
ConvMixer Model Implementation - Patch Embedding

Based on: "Patches Are All You Need?" by Trockman & Kolter (2022)

This file implements the Patch Embedding layer, which is the first
component of the ConvMixer architecture.

Date: 12/06/2025
Written by Zehao Li <zl3667@columbia.edu>

The code has not been generated by AI tools, or copied from an exteranal resource.
"""

import torch
import torch.nn as nn


class PatchEmbedding(nn.Module):
    """
    Patch Embedding Layer for ConvMixer.
    
    This layer divides the input image into non-overlapping patches
    and projects each patch to a high-dimensional embedding space.
    
    Implementation: Conv2d with kernel_size=patch_size and stride=patch_size
    
    Args:
        in_channels: Number of input channels (3 for RGB)
        embed_dim: Embedding dimension (hidden dimension h)
        patch_size: Size of each patch (p)
    
    Input shape: (batch, in_channels, H, W)
    Output shape: (batch, embed_dim, H/patch_size, W/patch_size)
    """
    
    def __init__(self, in_channels=3, embed_dim=256, patch_size=7):
        super(PatchEmbedding, self).__init__()
        
        self.patch_size = patch_size
        self.embed_dim = embed_dim
        
        # Patch embedding as strided convolution
        # kernel_size = patch_size, stride = patch_size
        self.proj = nn.Conv2d(
            in_channels, 
            embed_dim, 
            kernel_size=patch_size, 
            stride=patch_size
        )
        
        # Activation and normalization
        self.act = nn.GELU()
        self.norm = nn.BatchNorm2d(embed_dim)
    
    def forward(self, x):
        """
        Forward pass.
        
        Args:
            x: Input tensor of shape (batch, in_channels, H, W)
        
        Returns:
            Patch embeddings of shape (batch, embed_dim, H/p, W/p)
        """
        # Project patches to embedding dimension
        x = self.proj(x)
        
        # Activation and normalization
        x = self.act(x)
        x = self.norm(x)
        
        return x


def test_patch_embedding():
    """Test the PatchEmbedding module."""
    print("Testing PatchEmbedding...")
    
    # Test configurations
    configs = [
        {'patch_size': 1, 'embed_dim': 256, 'input_size': 32},   # CIFAR-10 p=1
        {'patch_size': 2, 'embed_dim': 256, 'input_size': 32},   # CIFAR-10 p=2
        {'patch_size': 4, 'embed_dim': 256, 'input_size': 32},   # CIFAR-10 p=4
        {'patch_size': 7, 'embed_dim': 768, 'input_size': 224},  # ImageNet p=7
    ]
    
    for cfg in configs:
        patch_embed = PatchEmbedding(
            in_channels=3,
            embed_dim=cfg['embed_dim'],
            patch_size=cfg['patch_size']
        )
        
        # Create dummy input
        x = torch.randn(2, 3, cfg['input_size'], cfg['input_size'])
        
        # Forward pass
        out = patch_embed(x)
        
        # Expected output size
        expected_size = cfg['input_size'] // cfg['patch_size']
        
        print(f"  patch_size={cfg['patch_size']}, embed_dim={cfg['embed_dim']}")
        print(f"    Input: {x.shape} -> Output: {out.shape}")
        print(f"    Expected spatial size: {expected_size}x{expected_size}")
        
        # Verify output shape
        assert out.shape == (2, cfg['embed_dim'], expected_size, expected_size), \
            f"Shape mismatch! Expected {(2, cfg['embed_dim'], expected_size, expected_size)}"
    
    print("\nAll PatchEmbedding tests passed!")


if __name__ == "__main__":
    test_patch_embedding()
